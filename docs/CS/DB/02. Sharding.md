---
sidebar_position: 2
---

## Concept
- 동일한 스키마를 가지고 있는 여러 데이터베이스 서버들에 데이터들을 일정 단위(Shard)로 분산 저장하는 기법
- 각 데이터베이스 파티션(partition)들을 서로 다른 데이터베이스 서버에 저장
- 개념적으로 한 데이터베이스를 각 서버에 물리적으로 분할하여 부하(Load) 분산

## Purpose
- 트래픽 분산
- 어플리케이션 반응 속도 개선

## Requirements
- Sharding Key
	- 각 서버에 있는 테이블들은 개념적으로 한 테이블 내에 있는 것이지만, 어떤 DB서버에 저장되어있는지 샤딩 키를 구현하여 추적할 수 있어야 한다.

## Horizontal Partitioning VS Sharding
- 샤딩은 수평 파티셔닝의 일종
- 물리 구현 형태가 다름
	- 수평적 파티셔닝 : 동일한 DB 서버 내에서 테이블을 분할
	- 샤딩 : DB 서버 자체를 분할
		- 데이터베이스 차원의 수평 확장
- 샤딩의 경우 DBMS가 공식 지원하지 않는다면 인덱스와 같은 성능 측면에서 손해를 볼 수도 있음

## Pros & Cons
### Pros
- Easy Scale Out
	- 샤드를 추가할 때 별개로 샤드 구성해서 붙여주면 되기 때문에 상대적으로 Scale Out이 간단함
- 데이터 스캔 범위 축소
- 샤드 단위 장애
	- 단일 장애 지점(SPOF, Single Point Of Failure)가 아니라서 전면 장애로 이어지지 않음
### Cons
- 프로그래밍 복잡도 증가
- Hot Spot(데이터의 특정 샤드 집중) 발생 시 단일 DB 구성과 다를 게 없어짐
	- 아래 Range Sharding에서 예시 설명
- 여러 샤드에 걸친 데이터 조인이 어려움

## Types
### Hash Sharding
### Modular Sharding
PK를 모듈러 연산(나머지 연산) 결과를 샤딩 키로 사용하여 라우팅
다만 데이터베이스 개수에 변화가 있으면 해시 함수 변경 및 샤딩 키 변동으로 인해 데이터 재정렬이 필요한 것은 비용측면의 손해

### Range Sharding
파티셔닝과 동일하게 특정 범위로 데이터베이스를 샤딩하는 방법
적절한 Range 기준을 설정하는 것이 중요하다.

단순한 예시로 연도 기준으로 유저 테이블에 샤딩을 설정했다고 가정하자. 2020~2024년까지는 어플리케이션이 흥행하지 못해 월 100명 정도의 유저 데이터만 유입되었다. 이후 2025년에 앱의 갑작스런 흥행으로 몇 백배의 유저가 유입되었다면 현재 구조의 샤딩에서 2025년에 해당하는 샤드에만 데이터가 집중, Hot Spot이 발생할 것이다. 이때는 새로운 기준을 설정하여 재-샤딩(re-sharding)해야 한다.

### Directory Sharding
별도 조회 테이블을 구성하여 라우팅하는 방식
위와 같이 단순한 방식이 아닌 직접 알고리즘 적용 및 시스템을 별개로 적용할 수 있다.
모든 DB 조회 전 조회 테이블을 참조해야 하므로 오버헤드가 발생한다.
샤드를 동적으로 추가하는 것이 상대적으로 쉽다.


## Refrences
- https://velog.io/@kyeun95/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%83%A4%EB%94%A9Sharding%EC%9D%B4%EB%9E%80
- https://hudi.blog/db-partitioning-and-sharding/
- https://jaehoney.tistory.com/245