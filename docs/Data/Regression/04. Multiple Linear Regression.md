---
sidebar_position: 4
---

# Multiple Linear Regression

Assume that we have a dataset with $n$ observations and $p$ variables. Let $\pmb y = (y_1, y_2, \ldots, y_n)^T$ and $X = (\pmb x_1^T, \pmb x_2^T, \ldots, \pmb x_n^T)^T$, where $\pmb x_i = (x_{i1}, x_{i2}, \ldots, x_{ip})^T$ for $i = 1, 2, \ldots, n$. 

## Multiple linear regression with matrix notation

Let the regression coefficient be $\pmb \beta$

$\pmb y = X \pmb \beta + \pmb \epsilon$ where $\pmb \epsilon \overset{iid}{\sim} (\pmb 0,\sigma^2 I_n)$
- $E(\pmb y) = E(X \pmb \beta + \pmb \epsilon) = X\pmb \beta + \pmb 0 = X \pmb \beta$.
- $Var(\pmb y) = Var(X \pmb \beta + \pmb \epsilon) = Var(\pmb \epsilon) = \sigma^{2} I_n$.
- $\therefore \pmb y \sim (X \pmb \beta, \sigma^{2} I_n).$


